import sys
import os 

#setting the path to the project root
script_path = os.path.abspath(__file__)
project_folder = os.path.abspath(os.path.join(os.path.dirname(script_path), '..'))
sys.path[0] = project_folder

# print(sys.path)
import numpy as np
from utils.colmap_script import read_cameras_binary

import torch
from datasets.image_loader import ImageLoader

def get_cam_txt(dir: str) -> np.ndarray:
    '''
    This function converts the cameras.bin file generated by colmap undistort image command
    and creates the intrinsic camera matrix and saves it as cam.txt file.

    params:
        dir: path to the folder where colmap saved after undistorting images.
            should contain images, sparse etc. folder
    
    Returns:
        intrinsic_matrix: 3x3 np array representing camera intrinsic matrix
    
    '''
    try:
        assert  os.path.exists(os.path.join(dir, 'sparse/cameras.bin'))
    except:
        print(f"{os.path.join(dir, 'sparse/cameras.bin')} does not exist.")
        raise ValueError(f"Folder {os.path.join(dir, 'sparse/cameras.bin')} does not exist.")


    cameras = read_cameras_binary(os.path.join(dir, 'sparse/cameras.bin'))
    for x in cameras:
        assert cameras[x].model=='PINHOLE'
        assert len(cameras[x].params)==4

        fx = cameras[x].params[0]
        fy = cameras[x].params[1]
        cx = cameras[x].params[2]
        cy = cameras[x].params[3]

        intrinsic_matrix = np.array([[fx, 0, cx],[0, fy, cy], [0, 0, 1]])
        return intrinsic_matrix
        # np.savetxt(os.path.join(dir, 'images/cam.txt'), intrinsic_matrix)


@torch.no_grad() 
def get_image_stats(dataset, batch_size:int = 10, stat_all:bool=False):
    '''
    get statistics of the dataset for normalizing.
    
    params:
        dataset (pytorch dataset class): a pytroch dataset class instance that returns images
        batch_size (int): batch size for the dataloader
    '''
    
    loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)

    # placeholders
    ch_1_sum = 0
    ch_2_sum = 0
    ch_3_sum = 0

    ch_1_sq_sum = 0
    ch_2_sq_sum = 0
    ch_3_sq_sum = 0

    #calculating mean and std for each channel separately

    # loop through images
    _,w,h = dataset[0].shape

    for data in loader:
        for images in data[0]:
            ch_1_sum += images[0].sum()
            ch_2_sum += images[1].sum()
            ch_3_sum += images[2].sum()

        # pixel count
        count = batch_size*w*h
        # mean and std
        ch1_mean = ch_1_sum/ count
        ch2_mean = ch_2_sum/ count
        ch3_mean = ch_3_sum/ count
        
        for images in data[0]:
            ch_1_sq_sum += ((images[0]-ch1_mean)**2).sum()
            ch_2_sq_sum += ((images[1]-ch1_mean)**2).sum()
            ch_3_sq_sum += ((images[2]-ch1_mean)**2).sum()

        
        if not stat_all:
            break


    #total pixel count
    if stat_all:
        count = len(dataset)*w*h
    else:
        count = batch_size*w*h

    # mean and std

    ch1_var  = (ch_1_sq_sum/ count)
    ch1_std  = torch.sqrt(ch1_var)

    ch2_var  = (ch_2_sq_sum/ count)
    ch2_std  = torch.sqrt(ch2_var)

    ch3_var  = (ch_3_sq_sum/ count)
    ch3_std  = torch.sqrt(ch3_var)

    # output
    print('mean: '  + str([ch1_mean.item(), ch2_mean.item(), ch3_mean.item()]))
    print('std:  '  + str([ch1_std.item(), ch2_std.item(), ch3_std.item()]))
    
    return {'mean': [ch1_mean.item(), ch2_mean.item(), ch3_mean.item()], 'std':[ch1_std.item(), ch2_std.item(), ch3_std.item()]}

if __name__=="__main__":
    print('!!!!!!!')
    dataset = ImageLoader()
    get_image_stats(dataset, stat_all=False)
    # mean: [0.11879350244998932, 0.11888326704502106, 0.11897549033164978]
    # std:  [0.004583629313856363, 0.004587945993989706, 0.004591305274516344]
    